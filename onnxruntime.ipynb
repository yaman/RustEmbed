{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping onnxruntime as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: onnx 1.14.1\n",
      "Uninstalling onnx-1.14.1:\n",
      "  Successfully uninstalled onnx-1.14.1\n",
      "Found existing installation: onnxruntime-gpu 1.16.0\n",
      "Uninstalling onnxruntime-gpu-1.16.0:\n",
      "  Successfully uninstalled onnxruntime-gpu-1.16.0\n",
      "Collecting onnxruntime-gpu\n",
      "  Obtaining dependency information for onnxruntime-gpu from https://files.pythonhosted.org/packages/8b/bb/550c2b3fa8c6a10af164354d74c07a5f3a3ef7c62ccdfe8d90576dea9edb/onnxruntime_gpu-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached onnxruntime_gpu-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting onnx\n",
      "  Obtaining dependency information for onnx from https://files.pythonhosted.org/packages/47/d4/f2d212558245e252b936247666c3f5981e6dba62ec470ff8be3df3389364/onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: coloredlogs in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (1.23.3)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (21.3)\n",
      "Requirement already satisfied: protobuf in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (4.21.7)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnx) (4.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Using cached onnxruntime_gpu-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153.4 MB)\n",
      "Using cached onnx-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "Installing collected packages: onnx, onnxruntime-gpu\n",
      "Successfully installed onnx-1.14.1 onnxruntime-gpu-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y onnxruntime onnx onnxruntime-gpu\n",
    "!pip install onnxruntime-gpu onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/search/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "session = ort.InferenceSession(\"/home/canavar/projects/embedding_rust_ort/fashion-clip-onnx/model.onnx\", providers=[\"CUDAExecutionProvider\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details: [<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c107bc30>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c107a9f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c104feb0>]\n",
      "input_ids tensor(int64)\n",
      "pixel_values tensor(float)\n",
      "attention_mask tensor(int64)\n",
      "Output Details: [<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c104fe30>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c1087330>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c1084f70>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f49c10852b0>]\n",
      "logits_per_image tensor(float)\n",
      "logits_per_text tensor(float)\n",
      "text_embeds tensor(float)\n",
      "image_embeds tensor(float)\n"
     ]
    }
   ],
   "source": [
    "input_details = session.get_inputs()\n",
    "output_details = session.get_outputs()\n",
    "\n",
    "print(\"Input Details:\", input_details)\n",
    "for input_detail in input_details:\n",
    "    print(input_detail.name, input_detail.type)\n",
    "\n",
    "print(\"Output Details:\", output_details)\n",
    "for output_detail in output_details:\n",
    "    print(output_detail.name, output_detail.type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Lednik7/CLIP-ONNX.git\n",
      "  Cloning https://github.com/Lednik7/CLIP-ONNX.git to /tmp/pip-req-build-korbgigq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Lednik7/CLIP-ONNX.git /tmp/pip-req-build-korbgigq\n",
      "  Resolved https://github.com/Lednik7/CLIP-ONNX.git to commit ebd4852b7d3ebf116709abf33b26832acaba947b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch==1.13.1 (from clip-onnx==1.2)\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.11.1 (from clip-onnx==1.2)\n",
      "  Obtaining dependency information for onnxruntime>=1.11.1 from https://files.pythonhosted.org/packages/26/f5/5f0aaf4cbd0017258619a0bfe117e1263035bd501a480eead0799c140025/onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: onnx>=1.11.0 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from clip-onnx==1.2) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torch==1.13.1->clip-onnx==1.2) (4.3.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->clip-onnx==1.2)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->clip-onnx==1.2)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->clip-onnx==1.2)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->clip-onnx==1.2)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->clip-onnx==1.2) (65.4.1)\n",
      "Requirement already satisfied: wheel in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->clip-onnx==1.2) (0.38.4)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnx>=1.11.0->clip-onnx==1.2) (1.23.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnx>=1.11.0->clip-onnx==1.2) (4.21.7)\n",
      "Requirement already satisfied: coloredlogs in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime>=1.11.1->clip-onnx==1.2) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime>=1.11.1->clip-onnx==1.2) (23.5.26)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime>=1.11.1->clip-onnx==1.2) (21.3)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime>=1.11.1->clip-onnx==1.2) (1.11.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.11.1->clip-onnx==1.2) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from packaging->onnxruntime>=1.11.1->clip-onnx==1.2) (3.0.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from sympy->onnxruntime>=1.11.1->clip-onnx==1.2) (1.3.0)\n",
      "Using cached onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "Building wheels for collected packages: clip-onnx\n",
      "  Building wheel for clip-onnx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip-onnx: filename=clip_onnx-1.2-py3-none-any.whl size=5738 sha256=c909b84e775543cee82c8281a72f006ac95786d85e2690f99576dba5cf421829\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gxq2gi90/wheels/cf/d1/ad/d5179665ed1668246e0023e05605fb6925058587c171472d53\n",
      "Successfully built clip-onnx\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, onnxruntime, nvidia-cudnn-cu11, torch, clip-onnx\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cpu\n",
      "    Uninstalling torch-1.12.1+cpu:\n",
      "      Successfully uninstalled torch-1.12.1+cpu\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "site-search 0.1.0 requires scipy==1.9.0, but you have scipy 1.11.1 which is incompatible.\n",
      "torchvision 0.13.1 requires torch==1.12.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed clip-onnx-1.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 onnxruntime-1.16.0 torch-1.13.1\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-pnrf2xkz\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-pnrf2xkz\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ftfy (from clip==1.0)\n",
      "  Using cached ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: regex in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from clip==1.0) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from clip==1.0) (4.64.1)\n",
      "Requirement already satisfied: torch in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from clip==1.0) (0.13.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torch->clip==1.0) (4.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torch->clip==1.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torch->clip==1.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (65.4.1)\n",
      "Requirement already satisfied: wheel in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.38.4)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torchvision->clip==1.0) (1.23.3)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torchvision->clip==1.0) (2.28.1)\n",
      "Collecting torch (from clip==1.0)\n",
      "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from torchvision->clip==1.0) (9.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from requests->torchvision->clip==1.0) (2022.9.24)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369497 sha256=e48920407873285f39361e2f2a4f11e674272fe57849ab6ef6301000fc4f17f0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uzedc_cu/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
      "Successfully built clip\n",
      "Installing collected packages: torch, ftfy, clip\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "clip-onnx 1.2 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
      "site-search 0.1.0 requires scipy==1.9.0, but you have scipy 1.11.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed clip-1.0 ftfy-6.1.1 torch-1.12.1\n",
      "Requirement already satisfied: onnxruntime-gpu in /opt/miniconda3/envs/search/lib/python3.10/site-packages (1.16.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (1.23.3)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (21.3)\n",
      "Requirement already satisfied: protobuf in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (4.21.7)\n",
      "Requirement already satisfied: sympy in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from onnxruntime-gpu) (1.11.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from packaging->onnxruntime-gpu) (3.0.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/miniconda3/envs/search/lib/python3.10/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Lednik7/CLIP-ONNX.git\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-08 06:13:23--  https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/openai/CLIP/raw/main/CLIP.png [following]\n",
      "--2023-10-08 06:13:23--  https://github.com/openai/CLIP/raw/main/CLIP.png\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png [following]\n",
      "--2023-10-08 06:13:23--  https://raw.githubusercontent.com/openai/CLIP/main/CLIP.png\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252444 (247K) [image/png]\n",
      "Saving to: ‘CLIP.png’\n",
      "\n",
      "CLIP.png            100%[===================>] 246,53K  1,50MB/s    in 0,2s    \n",
      "\n",
      "2023-10-08 06:13:24 (1,50 MB/s) - ‘CLIP.png’ saved [252444/252444]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c -O CLIP.png 'https://github.com/openai/CLIP/blob/main/CLIP.png?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "print(onnxruntime.get_device()) # priority device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# onnx cannot export with cuda\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=\"cpu\", jit=False)\n",
    "\n",
    "# batch first\n",
    "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).cpu() # [1, 3, 224, 224]\n",
    "image_onnx = image.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "# batch first\n",
    "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).cpu() # [3, 77]\n",
    "text_onnx = text.detach().cpu().numpy().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLIP ONNX] Start convert visual model\n",
      "[CLIP ONNX] Start check visual model\n",
      "[CLIP ONNX] Start convert textual model\n",
      "[CLIP ONNX] Start check textual model\n",
      "[CLIP ONNX] Models converts successfully\n"
     ]
    }
   ],
   "source": [
    "from clip_onnx import clip_onnx, attention\n",
    "# clip.model.ResidualAttentionBlock.attention = attention\n",
    "\n",
    "visual_path = \"clip_visual.onnx\"\n",
    "textual_path = \"clip_textual.onnx\"\n",
    "\n",
    "onnx_model = clip_onnx(model, visual_path=visual_path, textual_path=textual_path)\n",
    "onnx_model.convert2onnx(image, text, verbose=True)\n",
    "# ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "onnx_model.start_sessions(providers=[\"CUDAExecutionProvider\"]) # cpu mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = onnx_model.encode_image(image_onnx)\n",
    "text_features = onnx_model.encode_text(text_onnx)\n",
    "\n",
    "logits_per_image, logits_per_text = onnx_model(image_onnx, text_onnx)\n",
    "probs = logits_per_image.softmax(dim=-1).detach().cpu().numpy()\n",
    "\n",
    "print(\"Label probs:\", probs)  # prints: [[0.9927937  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
