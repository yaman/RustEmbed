{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/zsh: /opt/conda/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "\u001b[33mWARNING: Skipping onnxruntime as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: onnx 1.14.1\n",
      "Uninstalling onnx-1.14.1:\n",
      "  Successfully uninstalled onnx-1.14.1\n",
      "Found existing installation: onnxruntime-gpu 1.16.0\n",
      "Uninstalling onnxruntime-gpu-1.16.0:\n",
      "  Successfully uninstalled onnxruntime-gpu-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "/usr/bin/zsh: /opt/conda/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n",
      "Collecting onnxruntime-gpu\n",
      "  Obtaining dependency information for onnxruntime-gpu from https://files.pythonhosted.org/packages/37/05/2692ac789be375fd2b00194f3a7e3998333efa332289a66fcbde47b7021e/onnxruntime_gpu-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached onnxruntime_gpu-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting onnx\n",
      "  Obtaining dependency information for onnx from https://files.pythonhosted.org/packages/fd/57/7d606e47e38ba4c06b5d20b65e8805f74347758191c7a09b77dddc34f3aa/onnx-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached onnx-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.11/site-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.11/site-packages (from onnxruntime-gpu) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /opt/conda/lib/python3.11/site-packages (from onnxruntime-gpu) (1.26.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from onnxruntime-gpu) (23.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from onnxruntime-gpu) (3.20.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from onnxruntime-gpu) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.11/site-packages (from onnx) (4.7.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.11/site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Using cached onnxruntime_gpu-1.16.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153.4 MB)\n",
      "Using cached onnx-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "Installing collected packages: onnx, onnxruntime-gpu\n",
      "Successfully installed onnx-1.14.1 onnxruntime-gpu-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y onnxruntime onnx onnxruntime-gpu\n",
    "%pip install onnxruntime-gpu onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 17:37:33.812576232 [W:onnxruntime:, session_state.cc:1162 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2023-10-10 17:37:33.812587903 [W:onnxruntime:, session_state.cc:1164 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "session = ort.InferenceSession(\"fashion-clip-onnx/model.onnx\", providers=[\"CUDAExecutionProvider\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details: [<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bc4137470>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bd41d8cf0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bd43b7cb0>]\n",
      "input_ids tensor(int64)\n",
      "pixel_values tensor(float)\n",
      "attention_mask tensor(int64)\n",
      "Output Details: [<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bc41de070>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bc41dd730>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bc41438f0>, <onnxruntime.capi.onnxruntime_pybind11_state.NodeArg object at 0x7f8bc41415f0>]\n",
      "logits_per_image tensor(float)\n",
      "logits_per_text tensor(float)\n",
      "text_embeds tensor(float)\n",
      "image_embeds tensor(float)\n"
     ]
    }
   ],
   "source": [
    "input_details = session.get_inputs()\n",
    "output_details = session.get_outputs()\n",
    "\n",
    "print(\"Input Details:\", input_details)\n",
    "for input_detail in input_details:\n",
    "    print(input_detail.name, input_detail.type)\n",
    "\n",
    "print(\"Output Details:\", output_details)\n",
    "for output_detail in output_details:\n",
    "    print(output_detail.name, output_detail.type)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
